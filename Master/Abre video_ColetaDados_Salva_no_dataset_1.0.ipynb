{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Coleta de dados para a base<h2>\n",
    "_________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problema - Arrumar um modo de definir quando a coleta é ate o final do video e quando tem que colertar por frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alimentaDataframeBase(\"../Videos/Dormindo/\",pd.read_csv('Base_Normal.cvs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe_base = pd.read_csv('Base_Normal.cvs') #carrega dataframe base\n",
    "#dataframe_base = pd.read_csv('Base_Dormindo.cvs') #carrega dataframe base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector() #Face detector\n",
    "predictor = dlib.shape_predictor(\"../Dependencias/shape_predictor_68_face_landmarks.dat\") #preve os pontos do rosto\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)) #cria uma configuração para tratar imagem a partir do contrates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função recebe dataframe base e o caminho dos videos que será coletado os dados\n",
    "def alimentaDataframeBase(caminho_videos,dataframe,limit=-1):\n",
    "    for arquivo in os.listdir(caminho_videos): #passa pegando os nomes dos videos\n",
    "        dataframe.append(coletaDados(caminho_videos+arquivo,limit),ignore_index=True) #dataframe base recebe os dados coletados do video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coletaDados(arquivo_video,qtde_frame_Limite):\n",
    "\n",
    "    video_capture = cv2.VideoCapture(arquivo_video) #carrega o video na variavel\n",
    "\n",
    "    dadosDoVideoLinha = pd.DataFrame() #criar data frame vazio\n",
    "    dadosDoVideoDataframe = pd.DataFrame() #criar data frame vazio\n",
    "    currentFrame = 0       #controle de frame\n",
    "    semRosto = 0           #controle de frame sem rosto indentificado\n",
    "\n",
    "    while video_capture.grab(): #enquanto tiver frames\n",
    "        if (video_capture.get(cv2.CAP_PROP_FRAME_COUNT) == currentFrame):\n",
    "            return dadosDoVideoLinha\n",
    "            \n",
    "        currentFrame+=1\n",
    "\n",
    "        ret, frame = video_capture.retrieve()          #pega proximo quadro\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #passa a imagem para cinza\n",
    "        clahe_image = clahe.apply(gray)                #aplica uma configuração para melhor detecção\n",
    "        #cv2.imshow(\"image\", frame) #mostra a imagem\n",
    "\n",
    "        detections = detector(clahe_image, 1) #detecta as faces na imagem\n",
    "\n",
    "        if detections:\n",
    "            for k,d in enumerate(detections): #For each detected face\n",
    "                shape = predictor(clahe_image, d) #Get coordinates\n",
    "                for i in range(0,68): #There are 68 landmark points on each face\n",
    "                    dadosDoVideoLinha = pd.concat([dadosDoVideoLinha,pd.DataFrame({str(i+1)+'.x':[shape.part(i).x] ,str(i+1)+'.y':[shape.part(i).y]})],axis=1)\n",
    "        else:\n",
    "            semRosto = semRosto+1\n",
    "            \n",
    "        if(qtde_frame_Limite > -1 and qtde_frame_Limite == currentFrame): #se foi definido qtde_frame_Limite e ele foi atingido\n",
    "            qtde_frame_Limite*2 #dobra limite para o proximo corte\n",
    "            dadosDoVideoDataframe.append(dadosDoVideo,ignore_index=True) #Coleta dados da primeira linha no dataframe final\n",
    "            dadosDoVideoLinha = pd.DataFrame() #zera o data frame linha\n",
    "\n",
    "    video_capture.release() #fecha o arquivo do video carregado\n",
    "    \n",
    "    if(qtde_frame_Limite < 0):\n",
    "        return dadosDoVideoLinha\n",
    "    else:\n",
    "        return dadosDoVideoDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=3\n",
    "#linha2 = pd.DataFrame({str(i)+'.x':[3] ,str(i)+'.y':[2]})\n",
    "dataframe_base = pd.DataFrame()\n",
    "dataframe_Video = pd.DataFrame()\n",
    "\n",
    "dataframe_Video = pd.concat([dataframe_Video,pd.DataFrame({str(i)+'.a':[5] ,str(i)+'.b':[4]})],axis=1)\n",
    "\n",
    "#linha2 = pd.DataFrame({str(i)+'.a':[5] ,str(i)+'.b':[4]})\n",
    "#linha1 = pd.DataFrame({str(i)+'.a':[5] ,str(i)+'.b':[4]})\n",
    "\n",
    "linha1 = pd.concat([linha1, pd.DataFrame({str(i)+'.a':[5] ,str(i)+'.b':[4]})],axis=1)\n",
    "\n",
    "dataframe_base = dataframe_base.append(dataframe_Video,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3.a</th>\n",
       "      <th>3.b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   3.a  3.b\n",
       "0    5    4"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linha1.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linha = pd.DataFrame() #criar data frame vazio\n",
    "currentFrame = 1\n",
    "semRosto = 0\n",
    "while video_capture.grab(): #enquanto tiver quadros\n",
    "\n",
    "    currentFrame=currentFrame+1 #conta os frames\n",
    "    \n",
    "    ret, frame = video_capture.retrieve() #pega prximo quadro\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #passa a imagem para cinza\n",
    "    clahe_image = clahe.apply(gray) #aplica a configuração para melhor detecção\n",
    "    #cv2.imshow(\"image\", frame) #mostra a imagem\n",
    "    \n",
    "    detections = detector(clahe_image, 1) #detecta as faces na imagem\n",
    "\n",
    "    if detections:\n",
    "        for k,d in enumerate(detections): #For each detected face  \n",
    "            shape = predictor(clahe_image, d) #Get coordinates\n",
    "            for i in range(0,68): #There are 68 landmark points on each face\n",
    "            #cv2.circle(frame, (shape.part(i).x, shape.part(i).y), 1, (0,255,0), thickness=-1) #For each point, draw a red circle with thickness2 on the original frame            \n",
    "                ##linha = linha.append(pd.Series([shape.part(i).x,shape.part(i).y]),ignore_index=True) #adiciona as cordenadas no vetor\n",
    "                linha = pd.concat([linha,pd.DataFrame({str(i+1)+'.x':[shape.part(i).x] ,str(i+1)+'.y':[shape.part(i).y]})],axis=1) \n",
    "\n",
    "    #cv2.putText(frame, str(shape.part(1).x), (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "    else:\n",
    "        semRosto = semRosto+1\n",
    "\n",
    "        \n",
    "dataframe_base.append(linha,ignore_index=True) #adiciona um linha com os valores do vetor\n",
    "\n",
    "video_capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture.get(cv2.CAP_PROP_POS_FRAMES) #frame atual do video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture.get(cv2.CAP_PROP_FRAME_COUNT) #total de frames do video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Total de Frame do video \n",
    "\n",
    "160\n",
    "\n",
    "5 seg de 30fps\n",
    "150 frames no total\n",
    "\n",
    "\n",
    "total de frame - current frame > 150\n",
    "\n",
    "toral de frames restante tem que dar mais 5 segundos de video\n",
    "\n",
    "\n",
    "Se for varios videos\n",
    "coleta os 5 segundo\n",
    "adiciona no dataframe base\n",
    "e vai pro proximo...\n",
    "\n",
    "Se for video grande\n",
    "coleta os 5 segundos\n",
    "valida se tem frame suficiente pra mais um ciclo\n",
    "se tem\n",
    "   adiciona no datafrmae base\n",
    "   limpa data set linha\n",
    "   continua coleta\n",
    "Se ñ tem\n",
    "    adiciona no datafrmae base\n",
    "e acaba...\n",
    "\n",
    "Variaveis\n",
    "segundos de coleta. \n",
    "fps considerado.\n",
    "dataset base\n",
    "caminho dos ou do video"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
